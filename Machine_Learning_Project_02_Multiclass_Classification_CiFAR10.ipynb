{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing some functions\n",
    "from csv import reader\n",
    "from random import randrange\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load csv:\n",
    "def load_csv(filename):\n",
    "\tdataset = list() \n",
    "\twith open(filename, 'r') as file:\n",
    "\t\tcsv_reader = reader(file)\n",
    "\t\tfor col in csv_reader:\n",
    "\t\t\tif not col:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tdataset.append(col) #Fetching the value in the dataset from file\n",
    "\treturn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#String column to float operaton:\n",
    "def str_column_to_float(dataset, column):\n",
    "\tfor col in dataset:\n",
    "\t\tcol[column] = float(col[column].strip())   #Using the Strip Function for this operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching the file from the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21613"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the required CSV file from the system:      \n",
    "filename = 'data2.csv'\n",
    "dataset = load_csv(filename)\n",
    "len(dataset)              #Length of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset[0])):\n",
    "\tstr_column_to_float(dataset, i)     #Converting string column to float values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of data in input and output variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Input and Ouput Features of Dataset:\n",
    "X = [row[1:9] for row in dataset]\n",
    "Y = [row[0] for row in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21613"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)    #Length of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21613"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)   #Length of Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling of all the input features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the data as there was a lot of difference in the scales of the parameters:\n",
    "for i in range(len(X[0])):\n",
    "    for index, item in enumerate(X):\n",
    "        try:\n",
    "            X[index][i] = int(item[i])\n",
    "        except Exception as e:\n",
    "            X[index][i] = 0\n",
    "\n",
    "\n",
    "    max_val = max([row[i] for row in X])\n",
    "    min_val = min([row[i] for row in X])\n",
    "    for index, item in enumerate(X):\n",
    "        try:\n",
    "            X[index][i] = (item[i]-min_val)/(max_val-min_val) #Formula to get the scaling between 0 and 1\n",
    "        except Exception as e:\n",
    "            X[index][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21613"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the Scaled values of X:\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21613"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Defining X as XX for our convenience:\n",
    "XX=X\n",
    "len(XX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a train and test set:\n",
    "def train_test_split1(XX, split = 0.8):  #split is 0.8 to keep the division as 80% training data and 20% for testing.\n",
    "\tX_train = list()\n",
    "\tX_train_size = split * len(XX)      #Splitting into training and test set\n",
    "\tdataset_copy = list(XX)           #Keeping a copy of the data in XX\n",
    "\twhile len(X_train) < X_train_size:\n",
    "\t\tindex = randrange(len(dataset_copy))\n",
    "\t\tX_train.append(dataset_copy.pop(index))   #Now the training data set is fetched into the copied dataset.\n",
    "\treturn X_train, dataset_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4322"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test = train_test_split1(XX)\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a train and test set:\n",
    "def train_crossvalidation_split2(X_train, split = 0.75):  #split is 0.75 to keep the division as 75% training data and 25% for crossvalidation.\n",
    "\tX_crossv = list()\n",
    "\tX_crossv_size = split * len(X_train)       #Splitting into training and cross-validation set\n",
    "\tdataset_copy = list(X_train)           #Keeping a copy of the data in X_train\n",
    "\twhile len(X_crossv) < X_crossv_size:\n",
    "\t\tindex = randrange(len(dataset_copy))\n",
    "\t\tX_crossv.append(dataset_copy.pop(index))   #Now the training data set is fetched into the copied dataset.\n",
    "\treturn X_crossv, dataset_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_set,X_crossvalidation_set = train_crossvalidation_split2(X_train)    #Splitting the data finally for X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the number of examples and the division of Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12969"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Length of test set:\n",
    "len(X_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4322"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Length of Training set\n",
    "len(X_crossvalidation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4322"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into test set for finding Y_test:\n",
    "def train_test_split3(Y, split = 0.8):  #split is 0.8 to keep the division as 80% training data and 20% for testing.\n",
    "\tY_train = list()\n",
    "\tY_train_size = split * len(Y)      #Splitting into training and test set\n",
    "\tdataset_copy = list(Y)           #Keeping a copy of the data in Y\n",
    "\twhile len(Y_train) < Y_train_size:\n",
    "\t\tindex = randrange(len(dataset_copy))\n",
    "\t\tY_train.append(dataset_copy.pop(index))   #Now the training data set is fetched into the copied dataset.\n",
    "\treturn Y_train, dataset_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train,Y_test = train_test_split3(Y) #Train-Test Split for Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17291"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)  #Length of Training set for Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4322"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_test)   #length of Testing Set for Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a train and crossvalidation set for Y_train and Y_crossvalidate:\n",
    "def train_crossvalidation_split4(Y_train, split = 0.75):  #split is 0.75 to keep the division as 75% training data and 25% for crossvalidation.\n",
    "\tY_crossv = list()\n",
    "\tY_crossv_size = split * len(Y_train)      #Splitting into training and cross-validation set\n",
    "\tdataset_copy = list(Y_train)           #Keeping a copy of the data in Y_train \n",
    "\twhile len(Y_crossv) < Y_crossv_size:\n",
    "\t\tindex = randrange(len(dataset_copy))\n",
    "\t\tY_crossv.append(dataset_copy.pop(index))   #Now the training data set is fetched into the copied dataset.\n",
    "\treturn Y_crossv, dataset_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_set, Y_crossvalidation_set = train_crossvalidation_split4(Y_train) #Split for cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the number of examples and the division of Output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12969"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train_set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4322"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_crossvalidation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4322"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting data into int type for proper use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting X_train and X_test to float type\n",
    "for i in range(len(X_train_set[0])):\n",
    "    for index, item in enumerate(X_train_set):\n",
    "        try:\n",
    "            X_train_set[index][i] = float(item[i])\n",
    "        except Exception as e:                  #exception handling in case any error occur \n",
    "            X_train_set[index][i] = 0\n",
    "    for index, item in enumerate(X_test):\n",
    "        try:\n",
    "            X_test[index][i] = float(item[i])\n",
    "        except Exception as e:\n",
    "            X_test[index][i] = 0\n",
    "\n",
    "#Converting X_train and X_test to int type \n",
    "for i in range(len(X_train_set[0])):\n",
    "    for index, item in enumerate(X_train_set):\n",
    "        try:\n",
    "            X_train_set[index][i] = int(item[i])\n",
    "        except Exception as e:\n",
    "            X_train_set[index][i] = 0\n",
    "    for index, item in enumerate(X_test):\n",
    "        try:\n",
    "            X_test[index][i] = int(item[i])\n",
    "        except Exception as e:\n",
    "            X_test[index][i] = 0\n",
    "            \n",
    "#Converting Y_train and Y_test to float type \n",
    "for j,y in enumerate(Y_train_set):\n",
    "        try:\n",
    "            Y_train_set[j] = float(y)\n",
    "        except:\n",
    "            Y_train_set[j]=0\n",
    "for j, y in enumerate(Y_test):\n",
    "        try:\n",
    "            Y_test[j] = float(y)\n",
    "        except:\n",
    "            Y[j]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Hypothesis Function for Training data:\n",
    "def Hypothesis_Fn(X_train_set, thetas):\n",
    "    theta = 0\n",
    "    y_pred = 0\n",
    "    for weight in thetas:\n",
    "        if theta == 0:\n",
    "            y_pred =y_pred + weight\n",
    "        else:\n",
    "            y_pred =y_pred + weight*X_train_set[theta-1]\n",
    "        theta += 1\n",
    "    return y_pred\n",
    "thetas = [6,3,4,5,5,5,9,9,1]\n",
    "alpha = 0.00005\n",
    "#Cost Function for the training set of the model:\n",
    "def Cost_Fn_for_training(X_train_set, Y_train_set):\n",
    "    m = len(X_train_set)\n",
    "    J_theta = 0\n",
    "    for a,b in enumerate(X_train_set):\n",
    "        cost = Hypothesis_Fn(b,thetas)-Y_train_set[a]\n",
    "        cost += cost*cost\n",
    "        J_theta += cost\n",
    "    J_theta = (1/(2*m))*J_theta\n",
    "    return J_theta\n",
    "\n",
    "\n",
    "#Regularization\n",
    "l = 5\n",
    "def Regualrization(X_train_set, Y_train_set):\n",
    "    summ = 0\n",
    "    m = len(X_train_set)\n",
    "    for i,weight in enumerate(thetas):\n",
    "        summ += thetas[i]*thetas[i]\n",
    "    regularization = (l/(2*m))*summ\n",
    "    J_theta = Cost_Fn_for_training(X_train_set,Y_train_set)\n",
    "    cost = J_theta + regularization\n",
    "    return cost\n",
    "\n",
    "#Gradient Descent for Regularized Thetas:\n",
    "def Gradient_Descent(X_train_set, Y_train_set, epoch):\n",
    "    m = len (X_train_set)\n",
    "    J_theta = 0\n",
    "    for a,b in enumerate(X_train_set):\n",
    "        cost = Hypothesis_Fn(b,thetas)-Y_train_set[a]\n",
    "        if epoch == 0:\n",
    "            J_theta = cost\n",
    "        else:\n",
    "            J_theta += (cost*b[epoch-1])\n",
    "    J_theta += (1/m)*J_theta\n",
    "    return J_theta\n",
    "\n",
    "#Update values of thetas:\n",
    "def Update_thetas(X_train_set,Y_train_set):\n",
    "    m = len(X_train_set)\n",
    "    for a,b in enumerate(thetas):\n",
    "        thetas[a] = thetas[a] - alpha*(Gradient_Descent(X_train_set,Y_train_set,a) + ((l/m)*thetas[a]))\n",
    "        \n",
    "#Training:\n",
    "cost =[]\n",
    "def Training_model(X_train_set, Y_train_set, epoch):\n",
    "    for a in range(epoch):\n",
    "        J_theta = Regualrization(X_train_set,Y_train_set)\n",
    "        cost.append(J_theta)\n",
    "        print(a,J_theta)\n",
    "        Update_thetas(X_train_set,Y_train_set)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 211839889839.13998\n",
      "1 210585862251.26163\n",
      "2 209443219441.51648\n",
      "3 208401227668.9007\n",
      "4 207450208319.1947\n",
      "5 206581433352.41742\n",
      "6 205787031143.0855\n",
      "7 205059901678.86218\n",
      "8 204393640186.36246\n",
      "9 203782468345.41327\n",
      "10 203221172336.73203\n",
      "11 202705047043.03357\n",
      "12 202229845791.45554\n",
      "13 201791735085.8054\n",
      "14 201387253832.47928\n",
      "15 201013276612.89075\n",
      "16 200666980600.0346\n",
      "17 200345815756.63846\n",
      "18 200047477988.85458\n",
      "19 199769884961.1624\n",
      "20 199511154308.34702\n",
      "21 199269584005.99686\n",
      "22 199043634685.0589\n",
      "23 198831913697.23584\n",
      "24 198633160757.24557\n",
      "25 198446235005.27966\n",
      "26 198270103348.58633\n",
      "27 198103829955.14008\n",
      "28 197946566784.98077\n",
      "29 197797545056.25107\n",
      "30 197656067553.09216\n",
      "31 197521501691.91867\n",
      "32 197393273270.7934\n",
      "33 197270860834.18466\n",
      "34 197153790592.06033\n",
      "35 197041631838.3871\n",
      "36 196933992819.5577\n",
      "37 196830517008.1521\n",
      "38 196730879741.9246\n",
      "39 196634785191.84805\n",
      "40 196541963626.67133\n",
      "41 196452168944.65738\n",
      "42 196365176446.1073\n",
      "43 196280780822.85574\n",
      "44 196198794343.35062\n",
      "45 196119045213.97745\n",
      "46 196041376099.29346\n",
      "47 195965642785.4409\n",
      "48 195891712972.7308\n",
      "49 195819465184.59613\n",
      "50 195748787781.53394\n",
      "51 195679578069.6885\n",
      "52 195611741494.81152\n",
      "53 195545190913.19495\n",
      "54 195479845932.06094\n",
      "55 195415632312.61203\n",
      "56 195352481429.61417\n",
      "57 195290329781.98175\n",
      "58 195229118549.39893\n",
      "59 195168793190.54056\n",
      "60 195109303078.74533\n",
      "61 195050601171.62802\n",
      "62 194992643711.26962\n",
      "63 194935389952.03052\n",
      "64 194878801913.364\n"
     ]
    }
   ],
   "source": [
    "cost = []\n",
    "Training_model(X_train_set,Y_train_set,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot for Training with respect to cost calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(100),cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Cross Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_Validation(X_crossvalidation_set, Y_crossvalidation_set):           #measuring how well model is performing (minimum mean well)\n",
    "    m = len(X_crossvalidation_set)\n",
    "    J_theta = 0\n",
    "    prediction=[]\n",
    "    for i, x in enumerate(X_crossvalidation_set):\n",
    "        costa = Hypothesis_Fn(x, thetas)- Y_crossvalidation_set[i]\n",
    "        cost = costa * costa\n",
    "        prediction.append(costa)\n",
    "        J_theta += cost\n",
    "    J_theta  = (1/(2*m))*J_theta                            #cost on test data \n",
    "    return J_theta,prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crossvalidate_predicted_cost,prediction=Cross_Validation(X_crossvalidation_set,Y_crossvalidation_set)\n",
    "Crossvalidate_predicted_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing_Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Testing(X_test, Y_test):           #measuring how well model is performing (minimum mean well)\n",
    "    m = len(X_test)\n",
    "    J_theta = 0\n",
    "    prediction=[]\n",
    "    for i, x in enumerate(X_test):\n",
    "        costa = Hypothesis_Fn(x, thetas)- Y_test[i]\n",
    "        cost = costa * costa\n",
    "        prediction.append(costa)\n",
    "        J_theta += cost\n",
    "    J_theta  = (1/(2*m))*J_theta                            #cost on test data \n",
    "    return J_theta,prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_predicted_cost,prediction = Testing(X_test,Y_test)\n",
    "test_set_predicted_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1,4,5,6,8,3,2,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prediction_Function(X, thetas):\n",
    "    theta = 0\n",
    "    y_pred = 0\n",
    "    for weight in thetas:\n",
    "        if theta == 0:\n",
    "            y_pred =y_pred + weight\n",
    "        else:\n",
    "            y_pred =y_pred + weight*X[theta-1]\n",
    "        theta += 1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction_Function(X,thetas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
